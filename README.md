# TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis

#### Yu Zhang, Wenxiang Guo, Changhao Pan, Dongyu Yao, Zhiyuan Zhu, Ziyue Jiang, Yuhan Wang, Tao Jin, Zhou Zhao | Zhejiang University

PyTorch Implementation of [TCSinger 2 (ACL 2025)](): Customizable Multilingual Zero-shot Singing Voice Synthesis.

[![GitHub Stars](https://img.shields.io/github/stars/AaronZ345/TCSinger2?style=social)](https://github.com/AaronZ345/TCSinger2)

We will provide our implementation in this repository in about two months.

Visit our [demo page](https://aaronz345.github.io/TCSinger2Demo/) for audio samples.

## News
- 2025.05: TCSinger 2 is accepted by ACL 2025!

## Key Features
- We present **TCSinger 2**, a multi-task multilingual zero-shot SVS model with style transfer and style control based on various prompts.
- We introduce the **Blurred Boundary Content Encoder** for robust modeling and smooth transitions of phoneme and note boundaries.
- We design the **Custom Audio Encoder** using contrastive learning to extract styles from various prompts, while the **Flow-based Custom Transformer** with Cus-MOE and F0, enhances synthesis quality and style modeling.
- Experimental results show that TCSinger 2 outperforms baseline models in subjective and objective metrics across multiple tasks: **zero-shot style transfer, multi-level style control, cross-lingual style transfer, and speech-to-singing style transfer**.


## Disclaimer ##

Any organization or individual is prohibited from using any technology mentioned in this paper to generate someone's singing without his/her consent, including but not limited to government leaders, political figures, and celebrities. If you do not comply with this item, you could be in violation of copyright laws.

 ![visitors](https://visitor-badge.laobi.icu/badge?page_id=AaronZ345/TCSinger2)

